
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Convolutional Neural Network - Part 1 &#8212; HUGS 2025 - Artificial Intelligence for Nuclear Physics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "cfteach/HUGS2025");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "ðŸ’¬ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'CNN_HUGS2025_01';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://cfteach.github.io/HUGS2025/CNN_HUGS2025_01.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Convolutional Neural Network - Part 2" href="CNN_HUGS2025_02.html" />
    <link rel="prev" title="(Tut 1) Deep Learning Deep Inelastic Scattering at EIC" href="NN_h1_reg_CF_2025.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>
<aside class="bd-header-announcement" aria-label="Announcement">
  <div class="bd-header-announcement__content">This page is being updated</div>
</aside>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo_2025.pdf" class="logo__image only-light" alt="HUGS 2025 - Artificial Intelligence for Nuclear Physics - Home"/>
    <script>document.write(`<img src="_static/logo_2025.pdf" class="logo__image only-dark" alt="HUGS 2025 - Artificial Intelligence for Nuclear Physics - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    AI/ML for Nuclear Physics HUGS 2025
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/1eFXv0KlBtPr8G8Aw_aDlZOIOHUPEuvzn/view?usp=share_link">(Lec 1, part A) A Brief Introduction to AI/ML</a></li>
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/1A39DZNMuUvabV8XyhJ2VSt4CYkNUEMxs/view?usp=share_link">(Lec 1, part B) AI/ML in Nuclear Physics</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.google.com/presentation/d/1GlcFOsytJsw6B0k8AXwuswUiuU8LYySbRgrC3bkRmhY/edit?usp=sharing">(Lec 2) CNN for Physics  by K. Suresh</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Old) Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/1ySR6KmDs7PM1tVcDYuQwvt0wXuv0WIyS/view">(Lec 1) AI/ML for Nuclear Physics - A High-Bias, Low-Variance Introduction</a></li>
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/1kjGhjYMtmQIz42_fRNfoudC7UoSUMS7t/view">(Lec 2) Leveraging AI/ML for the future Electron Ion Collider</a></li>
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/1e0-qNQUldvUZEKib367nltQgqNBNf9LJ/view">(Lec 2, extra) AI/ML activities at Jefferson Lab - Paving the way for the Electron Ion Collider</a></li>
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/19tPr009whWgTjSlm9yUSWsUcs62UWjye/view">(Lec 3) ePIC at EIC â€“ The First Large-Scale Experiment Designed with the AI Assistance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="NN_h1_reg_CF_2025.html">(Lec 1) Deeply Learning Deep Inelastic Scattering</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">(Lec 2) CNN - Part 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="CNN_HUGS2025_02.html">(Lec 2) CNN - Part 2</a></li>
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/drive/folders/1EyMKnJMEmBGZ-BRNbebIfpfI7j1OywqD?usp=share_link">(Lec 2) Dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Old) Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="NeuralNetwork_preflight.html">(Tut 1) "Pre-flight"</a></li>
<li class="toctree-l1"><a class="reference internal" href="exe3a_moo_EA_3obj.html">(Tut 2 - part a) AI-assisted design with MOEA</a></li>
<li class="toctree-l1"><a class="reference internal" href="exe3b_moo_BO_3obj.html">(Tut 2 - part b) AI-assisted design with MOBO</a></li>
<li class="toctree-l1"><a class="reference external" href="https://eic.ai/community">AI4EIC tutorials</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">[Pre-flight]</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://docs.google.com/presentation/d/1BV2-N-c1bq4yx1IsPMW4fhC9i1SCdRAU/edit?usp=sharing&amp;ouid=113195593718692427789&amp;rtpof=true&amp;sd=true"> Intro to Modeling, Linear Regression (lecture slides)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Day-1/GIT-course/intro_to_git.html">1. Brief course on <code class="docutils literal notranslate"><span class="pre">git</span></code></a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/VCS.html">1.1. Version Control System (VCS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/git_basics.html">1.2. What is Git?</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/git_configure.html">1.3. Configuring your <code class="docutils literal notranslate"><span class="pre">git</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Day-1/GIT-course/git_exercises.html">2. Exercises on <code class="docutils literal notranslate"><span class="pre">git</span></code></a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/Exercise-1.html">2.1. Exercise 1: Basic Git Commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/Exercise-2.html">2.2. Exercise 2: Commits, push and branches</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/Exercise-3.html">2.3. Advanced exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/GIT-course/Exercise-4.html">2.4. GitHub Actions and Workflow Tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="Day-1/VS-code.html">3. Installing Visual Studio Code</a></li>


<li class="toctree-l1 has-children"><a class="reference internal" href="Day-1/HPC-course/intro_to_HPC_HTC.html">6. Introduction to High Performance Computing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Day-1/HPC-course/intro_to_HPC.html">6.1. High Performance Computing</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/HPC-course/ssh_login.html">6.2. SSH into a Front-End Node Using Proxy Jump</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/HPC-course/file_systems_WM.html">6.3. William &amp; Mary Research Computing: File Systems Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="Day-1/HPC-course/SLURM_commands2.html">6.4. Introduction to SLURM</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Intro_DS.html">Introduction to Data Science (beginners)</a></li>
<li class="toctree-l1"><a class="reference internal" href="EIC-Visualization.html">Interactively Navigate the Pareto Front of the EIC Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="EIC-Summary.html">EIC Overview</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datasets / Modules</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/file/d/1Z-lUTZrHoqeKsYHf34gR3kF45bVM6XG7/view">(Lec 1) all-h1-rapgap.root</a></li>
<li class="toctree-l1"><a class="reference external" href="https://raw.githubusercontent.com/cfteach/HUGS23/main/other/intro_Data.py">(Lec 1) intro_Data.py</a></li>
<li class="toctree-l1"><a class="reference external" href="https://drive.google.com/drive/folders/1EyMKnJMEmBGZ-BRNbebIfpfI7j1OywqD?usp=share_link">(Lec 2) Dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Additional resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="referencesmc.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/cfteach/HUGS2025/blob/webpage-src/source_material/CNN_HUGS2025_01.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/cfteach/HUGS2025" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cfteach/HUGS2025/edit/webpage-src/source_material/CNN_HUGS2025_01.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cfteach/HUGS2025/issues/new?title=Issue%20on%20page%20%2FCNN_HUGS2025_01.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/CNN_HUGS2025_01.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Convolutional Neural Network - Part 1</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-building-blocks-of-convolutional-neural-networks">The building blocks of convolutional neural networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performing-discrete-convolutions-in-2d">Performing discrete convolutions in 2D</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-of-2d-convolution">An example of 2D convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-inputs-to-control-the-size-of-the-output-feature-maps">Padding inputs to control the size of the output feature maps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#determining-the-size-of-the-convolution-output">Determining the size of the convolution output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where">Where:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#subsampling-layers-pooling-layers">Subsampling layers â€“ Pooling layers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-everything-together-implementing-a-cnn">Putting everything together â€“ implementing a CNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multilayer-cnn-architecture-with-pytorch">The multilayer CNN architecture with PyTorch</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="convolutional-neural-network-part-1">
<h1>Convolutional Neural Network - Part 1<a class="headerlink" href="#convolutional-neural-network-part-1" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<section id="the-building-blocks-of-convolutional-neural-networks">
<h2>The building blocks of convolutional neural networks<a class="headerlink" href="#the-building-blocks-of-convolutional-neural-networks" title="Link to this heading">#</a></h2>
<p>CNN inspired by the functioning of the visual cortex in our brain.
Experiment in 1959 with an anesthetized cat.
Neurons respond differently after projecting different patterns of light in front of the cat.
Primary layers of the viual cortex detects edges and straight lines, highger order layers focus more on extracting complex shapes.</p>
<p>In CNN, early layers extract low-level features from the raw data, later layers (often fully connected as in MLP) use these features to predict a target value.</p>
<p>CNN typically perform well on image data.</p>
<p>CNN performs well on image-related tasks largely due to two ideas:</p>
<ul class="simple">
<li><p><strong>Sparse connectivity</strong>: A single element in the feature map (output of the convolutional layer) is connected to only a small patch of pixels. This is very different from MLP (connections to the whole image).</p></li>
<li><p><strong>Parameter sharing</strong>: The same weights are used for different patches of the input image using the same filter.</p></li>
</ul>
<p>CNN made of following layers:</p>
<ul class="simple">
<li><p>convolutional -&gt; have learnable parameters</p></li>
<li><p>subsampling (Pooling layers) -&gt; no learnable parameters</p></li>
<li><p>fully connected -&gt; have learnable parameters</p></li>
</ul>
</section>
<section id="performing-discrete-convolutions-in-2d">
<h2>Performing discrete convolutions in 2D<a class="headerlink" href="#performing-discrete-convolutions-in-2d" title="Link to this heading">#</a></h2>
<p>Convolution applies a small filter (kernel) over the input x, allowing it to detect local structures like edges, textures, and patterns.</p>
<p><img alt="2D convolution" src="https://miro.medium.com/v2/resize:fit:658/1*GcI7G-JLAQiEoCON7xFbhg.gif" /></p>
<p>Note that the demonstration of convolution is only done for 1 channel. But if there are more than one channels, the convolution is applied to each channel separately and summed up as shown in reference <a class="reference external" href="https://miro.medium.com/v2/resize:fit:1600/1*ciDgQEjViWLnCbmX-EeSrA.gif">here</a></p>
<p>The discrete <strong>2D convolution</strong> of an image <span class="math notranslate nohighlight">\( I \)</span> with a kernel (filter) <span class="math notranslate nohighlight">\( K \)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[
S(i, j) = (I * K)(i, j) = \sum_{m=-k}^{k} \sum_{n=-l}^{l} I(i - m, j - n) \cdot K(m, n)
\]</div>
<p><strong>Where</strong>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( S(i, j) \)</span>: Output value at position <span class="math notranslate nohighlight">\((i, j)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\( I(i - m, j - n) \)</span>: Input image pixel at offset <span class="math notranslate nohighlight">\((m, n)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\( K(m, n) \)</span>: Kernel value at <span class="math notranslate nohighlight">\((m, n)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\( k = \left\lfloor \frac{M}{2} \right\rfloor \)</span>, <span class="math notranslate nohighlight">\( l = \left\lfloor \frac{N}{2} \right\rfloor \)</span> for a kernel of size <span class="math notranslate nohighlight">\( M \times N \)</span>.</p></li>
</ul>
<p><strong>Notes</strong>:</p>
<ul class="simple">
<li><p>The kernel <span class="math notranslate nohighlight">\( K \)</span> is usually flipped horizontally and vertically (standard convolution).</p></li>
<li><p>Without flipping, the operation is <strong>cross-correlation</strong>, not convolution.</p></li>
<li><p>Padding is commonly applied to maintain output dimensions.</p></li>
</ul>
</section>
<section id="an-example-of-2d-convolution">
<h2>An example of 2D convolution<a class="headerlink" href="#an-example-of-2d-convolution" title="Link to this heading">#</a></h2>
<p>Consider the image below:</p>
<a class="reference internal image-reference" href="https://c8.alamy.com/comp/2C4JRDX/seamless-pattern-with-horizontal-and-vertical-black-lines-2C4JRDX.jpg"><img alt="Image of a pattern" src="https://c8.alamy.com/comp/2C4JRDX/seamless-pattern-with-horizontal-and-vertical-black-lines-2C4JRDX.jpg" style="width: 600px;" /></a>
<p>Let us apply 3x3 kernel to this image. To make it more intutive, let us apply a vertical edge kernel  and a horizontal edge kernel usually referred to as a <strong>sobel filter</strong>.</p>
<p>The vertical edge kernel is as follows:
$<span class="math notranslate nohighlight">\(
K_{\text{vertical}} = \begin{bmatrix}
-1 &amp; 0 &amp; 1 \\
-2 &amp; 0 &amp; 2 \\
-1 &amp; 0 &amp; 1
\end{bmatrix}
\)</span>$</p>
<p>and horizontal edge kernel is as follows:
$<span class="math notranslate nohighlight">\(
K_{\text{horizontal}} = \begin{bmatrix}
-1 &amp; -2 &amp; -1 \\
0 &amp; 0 &amp; 0 \\
1 &amp; 2 &amp; 1
\end{bmatrix}
\)</span>$</p>
<p>We can now perform the convolution operation as mentioned above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>



<span class="k">def</span> <span class="nf">convolve2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform a 2D convolution without using scipy or other libraries.</span>
<span class="sd">    Args:</span>
<span class="sd">        image (ndarray): 2D input image.</span>
<span class="sd">        kernel (ndarray): 2D kernel/filter.</span>
<span class="sd">    Returns:</span>
<span class="sd">        output (ndarray): 2D output after applying convolution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">kernel</span><span class="p">))</span>  <span class="c1"># flip the kernel</span>
    <span class="n">kh</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">kh</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kw</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="n">padded_image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">((</span><span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_h</span><span class="p">),</span> <span class="p">(</span><span class="n">pad_w</span><span class="p">,</span> <span class="n">pad_w</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ih</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iw</span><span class="p">):</span>
            <span class="n">region</span> <span class="o">=</span> <span class="n">padded_image</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">kh</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="n">kw</span><span class="p">]</span>
            <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">region</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span>

<span class="c1"># Download a vertical and horizontal pattern image</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://c8.alamy.com/comp/2C4JRDX/seamless-pattern-with-horizontal-and-vertical-black-lines-2C4JRDX.jpg&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;L&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="c1"># Define a vertical edge filter (Sobel)</span>
<span class="n">vertical_filter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                            <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Define a horizontal edge filter (Sobel)</span>
<span class="n">horizontal_filter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                              <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
                              <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Apply convolution</span>
<span class="n">vertical_edges</span> <span class="o">=</span> <span class="n">convolve2d</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">vertical_filter</span><span class="p">)</span>
<span class="n">horizontal_edges</span> <span class="o">=</span> <span class="n">convolve2d</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">horizontal_filter</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">vertical_edges</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Vertical Edges&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">horizontal_edges</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Horizontal Edges&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83092212d2b49270a434356a5ad92fa30c4b262266e4497588e176601bcff0f7.png" src="_images/83092212d2b49270a434356a5ad92fa30c4b262266e4497588e176601bcff0f7.png" />
</div>
</div>
<p><strong>Question</strong></p>
<p>Can you now, apply Gaussian blur to the image? Any guess on how the kernel would like? Also, can you perhaps think about an example of where you would use a Guassian blur ?</p>
<p><em>Answer</em></p>
<p>The Gaussian kernel is a 2D array of weights that is used to blur an image. The kernel is typically a square matrix with an odd number of rows and columns. The weights in the kernel are typically Gaussian distributions, which means that the weights are highest in the center of the kernel and decrease as you move away from the center.</p>
<p>An example of a Gaussian kernel is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
K_{\text{Gaussian}} = \frac{1}{9} \begin{bmatrix}
1 &amp; 2 &amp; 1 \\
2 &amp; 4 &amp; 2 \\
1 &amp; 2 &amp; 1
\end{bmatrix}
\end{split}\]</div>
<p>This kernel is a 3x3 matrix with weights that are all positive and sum to 1. The weights in the center of the kernel are the highest, and the weights decrease as you move away from the center.</p>
</section>
<section id="padding-inputs-to-control-the-size-of-the-output-feature-maps">
<h2>Padding inputs to control the size of the output feature maps<a class="headerlink" href="#padding-inputs-to-control-the-size-of-the-output-feature-maps" title="Link to this heading">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Why</span> <span class="pre">Padding</span> <span class="pre">Matters?</span></code></strong></p>
<ul class="simple">
<li><p>Prevents excessive shrinking of feature maps in deep networks.</p></li>
<li><p>Controls how much context the kernel sees near the edges.</p></li>
<li><p>Balances computational efficiency vs. accuracy.</p></li>
</ul>
<p><strong>1. <code class="docutils literal notranslate"><span class="pre">Full</span> <span class="pre">Padding</span></code></strong></p>
<ul class="simple">
<li><p><strong>Adds the most padding</strong> (zero-padding around the input).</p></li>
<li><p>The output is <strong>larger</strong> than the input.</p></li>
<li><p>Ensures that the kernel has a valid position even at the edges.</p></li>
</ul>
<p><strong>2. <code class="docutils literal notranslate"><span class="pre">Same</span> <span class="pre">Padding</span></code></strong> (Most common in CNNs)</p>
<ul class="simple">
<li><p><strong>Adds just enough padding</strong> so that the output size remains <strong>the same</strong> as the input size (assuming stride = 1).</p></li>
<li><p>This helps preserve spatial dimensions throughout the layers.</p></li>
</ul>
<p><strong>3. <code class="docutils literal notranslate"><span class="pre">Valid</span> <span class="pre">Padding</span></code></strong> (No Padding)</p>
<ul class="simple">
<li><p><strong>No padding is added</strong>, meaning the kernel only moves over the valid input positions.</p></li>
<li><p>The output is <strong>smaller</strong> than the input.</p></li>
</ul>
<p>Here is a demonstration of these padding types in 1D. For 2D (or n-D), the concept is the same.</p>
<p><img alt="Padding types" src="https://raw.githubusercontent.com/cfteach/NNDL_DATA621/webpage-src/DATA621/DATA621/images/Fig4_lec10.png" /></p>
</section>
<section id="determining-the-size-of-the-convolution-output">
<h2>Determining the size of the convolution output<a class="headerlink" href="#determining-the-size-of-the-convolution-output" title="Link to this heading">#</a></h2>
<p>The output size <span class="math notranslate nohighlight">\( o \)</span> of a convolution operation is given by the formula:</p>
<div class="math notranslate nohighlight">
\[
o = \left\lfloor \frac{n + 2p - m}{s} \right\rfloor + 1
\]</div>
</section>
<section id="where">
<h2>Where:<a class="headerlink" href="#where" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( o \)</span>: output size (number of elements along that dimension),</p></li>
<li><p><span class="math notranslate nohighlight">\( n \)</span>: input size (e.g., image width or height),</p></li>
<li><p><span class="math notranslate nohighlight">\( m \)</span>: filter/kernel size,</p></li>
<li><p><span class="math notranslate nohighlight">\( p \)</span>: amount of zero-padding applied to both sides,</p></li>
<li><p><span class="math notranslate nohighlight">\( s \)</span>: stride (step size for the kernel),</p></li>
<li><p><span class="math notranslate nohighlight">\( \lfloor \cdot \rfloor \)</span>: floor operation, which rounds down to the nearest integer.</p></li>
</ul>
</section>
<section id="interpretation">
<h2>Interpretation:<a class="headerlink" href="#interpretation" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Padding increases the effective input size.</p></li>
<li><p>Larger stride reduces the output size by skipping positions.</p></li>
<li><p>This formula is used <strong>per dimension</strong>, so apply it separately for width and height in 2D convolutions.</p></li>
</ul>
</section>
<section id="example">
<h2>Example:<a class="headerlink" href="#example" title="Link to this heading">#</a></h2>
<p>If you have an input of size 32, kernel size 5, padding 2, and stride 1:</p>
<div class="math notranslate nohighlight">
\[
o = \left\lfloor \frac{32 + 2 \cdot 2 - 5}{1} \right\rfloor + 1 = \left\lfloor \frac{31}{1} \right\rfloor + 1 = 31 + 1 = 32
\]</div>
<p>This gives the same output size as the input.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PyTorch version:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NumPy version: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PyTorch version: 2.6.0+cu124
NumPy version:  2.0.2
</pre></div>
</div>
</div>
</div>
</section>
<section id="subsampling-layers-pooling-layers">
<h2>Subsampling layers â€“ Pooling layers<a class="headerlink" href="#subsampling-layers-pooling-layers" title="Link to this heading">#</a></h2>
<p>Pooling layers are used to reduce the dimensionality of the feature maps. This helps to reduce the computational cost of the network and to make the network more robust to small variations in the input.</p>
<p>There are two types of pooling layers:</p>
<ol class="arabic simple">
<li><p>Max pooling: The max pooling layer takes the maximum value of the feature map.</p></li>
<li><p>Average pooling: The average pooling layer takes the average value of the feature map.</p></li>
</ol>
<p>The pooling layers are applied after the convolutional layers. The pooling layers do not have any trainable parameters.</p>
<p><img alt="Pooling layers" src="https://raw.githubusercontent.com/cfteach/NNDL_DATA621/webpage-src/DATA621/DATA621/images/Fig7_lec10.png" /></p>
</section>
<section id="putting-everything-together-implementing-a-cnn">
<h2>Putting everything together â€“ implementing a CNN<a class="headerlink" href="#putting-everything-together-implementing-a-cnn" title="Link to this heading">#</a></h2>
<p><strong>Working with multiple input or color channels</strong></p>
<p>In the following example:</p>
<ul class="simple">
<li><p>The input has 3 channels</p></li>
<li><p>Each filter has a depth of 3, matching the number of input channels.</p></li>
<li><p>The number of filters (C_out = 5) determines the number of output feature maps. Each filter produces one feature map, meaning the output has 5 feature maps.</p></li>
<li><p>A pooling operation (e.g., max pooling, average pooling) is applied.</p></li>
</ul>
<p>It reduces spatial dimensions while maintaining 5 feature maps</p>
<p><img alt="CNN workflow" src="https://raw.githubusercontent.com/cfteach/NNDL_DATA621/webpage-src/DATA621/DATA621/images/Fig8_lec10.png" /></p>
</section>
<section id="the-multilayer-cnn-architecture-with-pytorch">
<h2>The multilayer CNN architecture with PyTorch<a class="headerlink" href="#the-multilayer-cnn-architecture-with-pytorch" title="Link to this heading">#</a></h2>
<p><img alt="CNN architecture" src="https://raw.githubusercontent.com/cfteach/NNDL_DATA621/webpage-src/DATA621/DATA621/images/Fig10_lec10.png" /></p>
<p>N.b.:</p>
<ul class="simple">
<li><p><strong>Convolution</strong>: default values of stride=1, padding=0 [<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html">https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html</a>]</p></li>
<li><p><strong>Pooling</strong>: default value of stride = kernel size [<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html">https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html</a>]</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "cfteach/HUGS2025",
            ref: "webpage-src",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="NN_h1_reg_CF_2025.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(Tut 1) Deep Learning Deep Inelastic Scattering at EIC</p>
      </div>
    </a>
    <a class="right-next"
       href="CNN_HUGS2025_02.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Convolutional Neural Network - Part 2</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-building-blocks-of-convolutional-neural-networks">The building blocks of convolutional neural networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performing-discrete-convolutions-in-2d">Performing discrete convolutions in 2D</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-of-2d-convolution">An example of 2D convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-inputs-to-control-the-size-of-the-output-feature-maps">Padding inputs to control the size of the output feature maps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#determining-the-size-of-the-convolution-output">Determining the size of the convolution output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where">Where:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#subsampling-layers-pooling-layers">Subsampling layers â€“ Pooling layers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-everything-together-implementing-a-cnn">Putting everything together â€“ implementing a CNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multilayer-cnn-architecture-with-pytorch">The multilayer CNN architecture with PyTorch</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cristiano Fanelli
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  HUGS2025
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>